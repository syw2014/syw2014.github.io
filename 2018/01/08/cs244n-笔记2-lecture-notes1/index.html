<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="cs244n,NLP,DL,word2vec," />





  <link rel="alternate" href="/atom.xml" title="悯生" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="NLP IntroductionWhat is Nature Language Processing(NLP)?在AI 概念被广泛提及的今天，不得不提NLP-自然语言处理，那到底什么是NLP，它又有着怎样的目标和划分。NLP 是通向人工智能必不可少的一个环节。NLP 是一个多学科交叉的领域，它涵盖了ComputerScience、Artificial Intelligence、linguistic">
<meta name="keywords" content="cs244n,NLP,DL,word2vec">
<meta property="og:type" content="article">
<meta property="og:title" content="cs244n笔记2-lecture notes1:词向量Part 1">
<meta property="og:url" content="http://syw2014.github.io/2018/01/08/cs244n-笔记2-lecture-notes1/index.html">
<meta property="og:site_name" content="悯生">
<meta property="og:description" content="NLP IntroductionWhat is Nature Language Processing(NLP)?在AI 概念被广泛提及的今天，不得不提NLP-自然语言处理，那到底什么是NLP，它又有着怎样的目标和划分。NLP 是通向人工智能必不可少的一个环节。NLP 是一个多学科交叉的领域，它涵盖了ComputerScience、Artificial Intelligence、linguistic">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-625c2da681c71581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-fd91e9180a0ce831.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-3f71ec13e74334a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-f84f0b07a7eb47b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-bab5fcd1a6effd67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-9c2d582d49c1ff0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-2a8cc9aecc9b8188.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-45ac04302affc683.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-469fc7d7fefa6458.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-de5b3628321b608d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-a13b77844a043314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-2e01bb0e704fdcd3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-6ee4a375a16cb7cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-d877cd7e9d808c82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-4b5169e776a61d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-8b6c17afebc48a81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/2423131-e0d6bf64ff6fbe1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2018-01-20T13:46:34.849Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="cs244n笔记2-lecture notes1:词向量Part 1">
<meta name="twitter:description" content="NLP IntroductionWhat is Nature Language Processing(NLP)?在AI 概念被广泛提及的今天，不得不提NLP-自然语言处理，那到底什么是NLP，它又有着怎样的目标和划分。NLP 是通向人工智能必不可少的一个环节。NLP 是一个多学科交叉的领域，它涵盖了ComputerScience、Artificial Intelligence、linguistic">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/2423131-625c2da681c71581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: undefined,
      author: '博主'
    }
  };
</script>

  <title> cs244n笔记2-lecture notes1:词向量Part 1 | 悯生 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?ffb4a93df57204139bba53ccb1f4b2a0";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">悯生</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">正心 诚意 修身</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                cs244n笔记2-lecture notes1:词向量Part 1
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2018-01-08T21:41:37+08:00" content="2018-01-08">
              2018-01-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/course/" itemprop="url" rel="index">
                    <span itemprop="name">course</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/course/cs244n/" itemprop="url" rel="index">
                    <span itemprop="name">cs244n</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2018/01/08/cs244n-笔记2-lecture-notes1/" class="leancloud_visitors" data-flag-title="cs244n笔记2-lecture notes1:词向量Part 1">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
              &nbsp; | &nbsp;
              <span class="page-pv"><i class="fa fa-file-o"></i>
              <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
              </span>
          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="NLP-Introduction"><a href="#NLP-Introduction" class="headerlink" title="NLP Introduction"></a>NLP Introduction</h2><h3 id="What-is-Nature-Language-Processing-NLP"><a href="#What-is-Nature-Language-Processing-NLP" class="headerlink" title="What is Nature Language Processing(NLP)?"></a>What is Nature Language Processing(NLP)?</h3><p>在AI 概念被广泛提及的今天，不得不提NLP-自然语言处理，那到<br>底什么是NLP，它又有着怎样的目标和划分。NLP 是通向人工智能必不<br>可少的一个环节。NLP 是一个多学科交叉的领域，它涵盖了Computer<br>Science、Artificial Intelligence、linguistics; 做NLP 的目的是能够让<br>计算机能够理解“自然语言”从而去做一些有益的事情比如约会，购物和<br>助手比如Siri, Google Assistant, Facebook M, Cortana 等。很好的理解自<br>然语言有着很大的困难和挑战后面会具体叙述其原因。<br><a id="more"></a><br>根据NLP 研究层次的不同可以进行如下划。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-625c2da681c71581.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="NLP Level"></p>
<p>从图中可以看出，最基本的层次分为语音分析和文本OCR、切分，之<br>后是语态分析(分析某些元素所祈祷的作用)，之后是句法分析(对句子中<br>的词语语法功能进行分析)，再下一层是语义解释(分析每个成分在语义含<br>义层面的事情)，最后是语篇分析(所谓的终极理解)。各个问题都是研究的<br>NLP 的核心问题，难度和挑战也是逐层加大。虽然NLP 离完全AI 还有很<br>大距离，但当前的技术水平，以使它在各行业有了广泛的应用。</p>
<ul>
<li>拼写检查、关键词搜索、同义词查找</li>
<li>信息提取，如提取价格、日期、地点</li>
<li>文本分类、情感分析</li>
<li>机器翻译</li>
<li>对话系统，问答<br>在工业届很多实际场景中也得到广泛的应用。</li>
<li>搜索场景(语音和文字)</li>
<li>在线广告</li>
<li>自动、辅助翻译</li>
<li>市场情感分析</li>
<li>语音辨识</li>
<li>聊天对话系统(客服助手、设备控制、购物)<h3 id="What’s-so-special-about-human-nature-language"><a href="#What’s-so-special-about-human-nature-language" class="headerlink" title="What’s so special about human(nature) language?"></a>What’s so special about human(nature) language?</h3>人类语言后者称作自然语言被设计的初衷是用来携带、传达彼此之间<br>的信息，并不是由任何物理形成产生的，基于这一个特点，它不同于视觉、<br>图像处理或其他机器学习任务。举个具体的例子”rocket”, 这个词可以指代<br>火箭这个概念，同时也可以表示具体事物火箭。不同的说话语气也可以表<br>示不同的含义，比”Whooompaa”. 自然语言可以用多种形式进行表示，比<br>如声音、手势、书写，这些信息不断的通过信号传送到人的大脑中，这样<br>人才能去理解。NLP 的目标是通过设计算法让计算机能够理解自然语言并<br>帮助执行一些任务。根据任务难度不同，NLP 研究任务举例如下。<br>Easy</li>
<li>拼写检查</li>
<li>关键词搜索</li>
<li>同义词查找<br>Medium</li>
<li>文档解析<br>Hard</li>
<li>机器翻译</li>
<li>语义分析(分析某个query 的具体具体含义)</li>
<li>指代分析(分析一篇文档中指称代词具体指的什么)</li>
<li>问答系统</li>
<li>聊天机器人<br>那么为什么要引入深度学习呢？因为深度学习可以看成是一个强大的表示<br>学习系统，利用学到的representation 去解决NLP 相关的任务。现在问题<br>来了，如和去得到一个词的表示，这个表示以何种形式进行存在呢？经过<br>前人的探索和研究，将”word” 表示成vector 形式能够极大的促进任务的解<br>决，因为word 都以向量的形式进行表示，则可以进行距离方式(Jaccard,<br>Cosine, Euclidean) 进行计算。<h2 id="Word-Vector"><a href="#Word-Vector" class="headerlink" title="Word Vector"></a>Word Vector</h2>将word 表示成vector 对解决NLP Task 有着重要的帮助，如何将<br>word 转换为vector 呢？最直观的想法是建立一个vocabulary，然后将每<br>个word 都表示成一个vocab 大小的vector,vector 中只有在word 出现的<br>index 位置为1，其他位置全部为0，这种方式就是常说的基于BOW(bag<br>of words) 的one-hot编码。这种方式的缺陷显而易见，一是vocabulary 词<br>典很大，英文词典可达到13million，而中文词典更大；二是这种方式并不<br>能体现同义词之间的相近关系。根据one-hot encoding 的结果，计算任意<br>两个词间的点积，结果都是零，这就是体现了这种encoding 方式并不能体<br>现出词间的某种相似性。除one-hot encoding 之外，还有字符编码等。<h2 id="SVD-Based-Methods"><a href="#SVD-Based-Methods" class="headerlink" title="SVD Based Methods"></a>SVD Based Methods</h2>除了前面提到的one-hot encoding 之外还可以利用基于矩阵分解对的<br>方式来获得word vecotr(通常也称作word embedding)。这种方式有个前提<br>假设，“经常同时出现的词语义具有相似性，即词间的共现性。”首先我们<br>遍历一个大的document 库，目的是要构建一个word-document 矩阵。首<br>先构建个vocabulary，然后遍历每个word i在每个document j中出现的次<br>数，存放在Xij , 这样就形成了一个矩阵XRM,M 是总的文档数量。当构造<br>出word-doc 矩阵之后，利用SVD(Singular Value Decomposition) 对矩阵<br>进行分析，矩阵分解公式如下，<br><img src="http://upload-images.jianshu.io/upload_images/2423131-fd91e9180a0ce831.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></li>
</ul>
<p>进行矩阵分解之后，观察奇异值(对角矩阵S 中对角线上的值)，然后选取<br>k 个值，从而选择子矩阵U1:V;1:k 作为word embedding 矩阵，那么每个词<br>将表示成一个k-dimension 的vector。这中方式其实类似于LSA。但同时<br>这种方式也存在一些问题，如下：</p>
<ul>
<li>word-doc 矩阵经常变换，因为频繁会有新的词加入进来</li>
<li>整个矩阵会非常系数，因为有很多词并不共现</li>
<li>矩阵维度很大</li>
<li>SVD 复杂度是O(n2)</li>
<li>对于词频率不均衡需(有些词频率会很大) 要特殊处理<h2 id="Iteration-Based-Methods-Word2Vec"><a href="#Iteration-Based-Methods-Word2Vec" class="headerlink" title="Iteration Based Methods - Word2Vec"></a>Iteration Based Methods - Word2Vec</h2>换一种思维，设计一种模型，让模型的参数词向量，通过对模型的迭<br>代训练、误差优化、参数更新学到word vectors。在NLP 任务中，学者们<br>已尝试过很多中方式来实现这个目的。比如在特定的NLP 任务中，刚开<br>始时将每个word 转换为一个词向量，训练不仅仅更新模型参数同时也训<br>练word vector。(注：这在tensorflow 中是基于look table 实现)。这里介<br>绍一种更高效、简单的、概率的方法word2vec, 它是一个软件包，包含<br>两种算法CBOW(continuous bag-of-words) 和Skip-gram。前者是给定<br>context word 来预测center word，后者刚好相反；两种训练方法Negative<br>Sampling 和Hierarchical Softmax, 负采样通过负采样来定义目标函<br>数，分层softmax 通过一种高效的树结构计算词典中每个词概率来定义目<br>标函数。下文会对他们进行详细阐述。<h3 id="Continuous-Bag-of-Words-Model-CBOW"><a href="#Continuous-Bag-of-Words-Model-CBOW" class="headerlink" title="Continuous Bag of Words Model(CBOW)"></a>Continuous Bag of Words Model(CBOW)</h3>给定context word(上下文周边词) 来预测center word 的方式被称作<br>CBOW 模型。CBOW 网络结构如图所示。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-3f71ec13e74334a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Continuous bag of words model"><br>下面给出模型中一些必要的参数定义和说明：<br><img src="http://upload-images.jianshu.io/upload_images/2423131-f84f0b07a7eb47b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="http://upload-images.jianshu.io/upload_images/2423131-bab5fcd1a6effd67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></li>
</ul>
<p>在CBOW 中每个词会学习到两个vector，输入词向量vi 和输出词向量<br>uj，最终选择哪个作为后文会讨论。CBOW 模型执行具体过程如下.<br><img src="http://upload-images.jianshu.io/upload_images/2423131-9c2d582d49c1ff0a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>以上就是CBOW 模型具体执行过程，其中省略了梯度推导和计算.</p>
<h3 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h3><p><img src="http://upload-images.jianshu.io/upload_images/2423131-2a8cc9aecc9b8188.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>Skip-gram 是通过中心词来预测周围词的模型。skip-gram 网络模型如<br>图所示。skip-gram 模型过程基本与CBOW 类似，下面对该过程进行具体<br>介绍。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-45ac04302affc683.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>在CBOW 和Skip gram 模型中，采用生成的概率分布去预测词的真实分布，如何去评价模型的好坏呢？根据信息论我们知道，<br>cross entropy 是用来测度两个分布之间差异，因此在CBOW 和SG 模型<br>中也采用交叉熵作为目标函数。在SG 模型中，基于朴素贝叶斯假设，将<br>预测的上下文词的联合概率分布当做独立分布去计算。这里以SG 模型为<br>主，且词窗口设定为1，则目标函数为<br><img src="http://upload-images.jianshu.io/upload_images/2423131-469fc7d7fefa6458.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>其中，yi 是真是词向量，属于one-hot 编码只有在下标为c 处为1，而预<br>测概率by 是通过softmax 而来。以上就是最终的目标函数，可以基于此目<br>标函数对其中的输入参vc 和输出参数uc 就梯度，采用梯度下降法进行求<br>解最优值。各参数梯度求导可参考文献[1]</p>
<h3 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h3><p>回顾一下目标函数，整个词表的大小|V| 可能会很大，每次更新都需<br>要O(|V|) 的时间，我们设法对它进行优化，一个直观的想法是通过采样<br>来替代遍历整个词典。在每个训练步，通过采样一些负例来代替遍历整个<br>词典。采样原则基于某个分布Pn(w)，它的概率值与词典中词的频率顺序<br>相对应，换句话说就是频率高的词被采样概率越大。为了适应负采样做法<br>我们需要调整目标函数、梯度、更新规则。Negative Sampling 是Mikolov<br>在这篇Paper中进行论述. 负采样是基于Skip-gram 模型，但优化的目标函<br>数不同。给定一个词和上下文中的词构成的词对(w; c)，用P(D = 1jw; c)<br>表示词对来源于与语料库(这里语料库的意思是指w 是词c 的上下文词，<br>即在同一个窗口内)，记P(D = 0jw; c) 表示词对不是来自于语料库，用<br>sigmod 函数对前一种情况进行建模<br><img src="http://upload-images.jianshu.io/upload_images/2423131-de5b3628321b608d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>函数图像如下，它可以看成是Softmax 的1 维情况根据前面的描述，我们<br>设计一个新的目标函数，如果词和上下文来源于同一个语料库，则最大化<br>他们来源于同一个语料库的概率，如果不是，则最大化他们不是来源于同<br>一个语料库的概率，即最小化来源于同一语料库的概率。我们采用极大似<br>然函数法来表示这两个概率，<br><img src="http://upload-images.jianshu.io/upload_images/2423131-a13b77844a043314.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/2423131-2e01bb0e704fdcd3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="http://upload-images.jianshu.io/upload_images/2423131-6ee4a375a16cb7cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/2423131-d877cd7e9d808c82.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Hierarchical-Softmax"><a href="#Hierarchical-Softmax" class="headerlink" title="Hierarchical Softmax"></a>Hierarchical Softmax</h2><p>Mikolov 在这篇中同时也介绍了另外一个优化普通softmax 的方法<br>即使hierarchical softmax，分层softmax。在实践中，hierarchical softmax<br>对罕见词有较好的效果，而negative sampling 对高频词有较好的效果。<br>Hierarchical softmax 采用一个二叉树来表示词典中所有词如图所示。每一个叶子<br><img src="http://upload-images.jianshu.io/upload_images/2423131-4b5169e776a61d87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>节点都代表一个词，从根节点到leaf 节点只有唯一一条路径，这个路<br>径被定义为每个词的概率，图中除去根节点和叶子节点以外的节点，都<br>是一个需要模型学习的向量。当用Hierarchical softamx 时，整个模型中<br>每个词只有输入表示，而不像原始模型中那样也具有输出表示。下图是<br>Hierarchical softmax 二叉树的一个示例。在这个模型中，当给定一个向量<br>wi 和P(wjwi) 时，词w 的概率就等于从根节点出发随机游走到与w 相关<br>的叶子节点的概率。由于采用二叉树结构，所有模型计算复杂度从最初的<br>O(|V |) 变成O(log(|V |)). 为了进一步介绍该模型，引入一下记号，<br><img src="http://upload-images.jianshu.io/upload_images/2423131-8b6c17afebc48a81.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br><img src="http://upload-images.jianshu.io/upload_images/2423131-e0d6bf64ff6fbe1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>为了训练这个模型，我们的目标依然是最小化负对数似然函数<br>-logP(w|w_i)，但是我们只需要更新在二叉树中从根节点到叶子节点路<br>径上的节点的向量即可，而不需要更新每个词的输出向量。这个方法的速<br>度取决于如何构建二叉树及如何用叶子节点表示每个词，在MIKOLOV 的<br>论文中使用的是Huffman 树，它的特点是频率越高的词在树中路径越短。<br>5 参考文献<br>[Bengio et al., 2003] Bengio, Y., Ducharme, R., Vincent, P., and Janvin,<br>C. (2003). A neural probabilistic language model. J. Mach. Learn. Res.,<br>3:1137–1155. [Collobert et al., 2011] Collobert, R., Weston, J., Bottou,<br>L., Karlen, M., Kavukcuoglu, K., and Kuksa, P. P. (2011). Natural language<br>processing (almost) from scratch. CoRR, abs/1103.0398. [Mikolov<br>et al., 2013] Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013).<br>Efficient estimation of word representations in vector space. CoRR, abs/<br>1301.3781. [Rong, 2014] Rong, X. (2014). word2vec parameter learning<br>explained. CoRR, abs/1411.2738. [Rumelhart et al., 1988] Rumelhart, D.<br>E., Hinton, G. E., and Williams, R. J. (1988). Neurocomputing: Foundations<br>of research. chapter Learning Representations by Back-propagating<br>Errors, pages 696–699. MIT Press, Cambridge, MA, USA.</p>

      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/wechat.png" alt="悯生 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/alipay.png" alt="悯生 Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/cs244n/" rel="tag">#cs244n</a>
          
            <a href="/tags/NLP/" rel="tag">#NLP</a>
          
            <a href="/tags/DL/" rel="tag">#DL</a>
          
            <a href="/tags/word2vec/" rel="tag">#word2vec</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/12/11/Neo4j使用介绍/" rel="next" title="Neo4j使用介绍">
                <i class="fa fa-chevron-left"></i> Neo4j使用介绍
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/13/cs244n-笔记3-lecture3-高级词向量/" rel="prev" title="cs244n笔记3-lecture3:高级词向量">
                cs244n笔记3-lecture3:高级词向量 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/dasheng.jpg"
               alt="悯生" />
          <p class="site-author-name" itemprop="name">悯生</p>
          <p class="site-description motion-element" itemprop="description">悯此忘真契，声名无求处。诗书来不及，江海渺难分。</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">11</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              神奇链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://mskitech.com/about/" title="关于本站" target="_blank">关于本站</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://www.jianshu.com/u/c44c1c14b248" title="作者简书" target="_blank">作者简书</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#NLP-Introduction"><span class="nav-number">1.</span> <span class="nav-text">NLP Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-Nature-Language-Processing-NLP"><span class="nav-number">1.1.</span> <span class="nav-text">What is Nature Language Processing(NLP)?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What’s-so-special-about-human-nature-language"><span class="nav-number">1.2.</span> <span class="nav-text">What’s so special about human(nature) language?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word-Vector"><span class="nav-number">2.</span> <span class="nav-text">Word Vector</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SVD-Based-Methods"><span class="nav-number">3.</span> <span class="nav-text">SVD Based Methods</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Iteration-Based-Methods-Word2Vec"><span class="nav-number">4.</span> <span class="nav-text">Iteration Based Methods - Word2Vec</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Continuous-Bag-of-Words-Model-CBOW"><span class="nav-number">4.1.</span> <span class="nav-text">Continuous Bag of Words Model(CBOW)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Skip-gram"><span class="nav-number">4.2.</span> <span class="nav-text">Skip-gram</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Negative-Sampling"><span class="nav-number">4.3.</span> <span class="nav-text">Negative Sampling</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hierarchical-Softmax"><span class="nav-number">5.</span> <span class="nav-text">Hierarchical Softmax</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">悯生</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("6sEpjxpdQ0zFbHII2mSfaKib-gzGzoHsz", "qdahfkeMY3jcS1ebdMnOQr7I");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script type="text/javascript" async src="//push.zhanzhang.baidu.com/push.js">
</script>


</body>
</html>
