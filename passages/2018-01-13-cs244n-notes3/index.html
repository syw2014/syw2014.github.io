<!DOCTYPE html>
<html>
  
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta name="author" content="悯生" />
  
  
  <title>CS244n lecture3 Notes:高级词向量 | 踏路</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="CS244n,cs244n,NLP,DL,word2vec," />
  

  
  <meta name="description" content="cs244n第三次课是TA Richard Socher来完成，本次课程主要是对word2vec深入分析，理解word2vec将词表示成向量，背后真正学习到了什么，如何去把握，同时引出比w2v效果更好的Glove，最后又提到了一些如何评价word vector的方法。">

  

  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.1/dist/av-min.js" async></script>
  

  
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
  

  
    <script src="//unpkg.com/valine/dist/Valine.min.js" async></script>
  

  

  <script>
  // theme-ad's config script
  // it can be used in every script
  
  window.AD_CONFIG = {
    leancloud: {"appid":"6sEpjxpdQ0zFbHII2mSfaKib-gzGzoHsz","appkey":"qdahfkeMY3jcS1ebdMnOQr7I","comment":true,"count":true},
    welcome: {"enable":true,"interval":10},
    start_time: "2016-02-10",
    passwords: ["efe07af7441da2b69c4a41e42e73be4db47f66010a56900788a458354a7373ec", ],
    is_post: true,
    lock: false,
    author: "悯生",
    share: {"twitter":true,"facebook":true,"weibo":true,"qq":true,"wechat":true},
    mathjax: true,
    page_type: "",
    root: "/"
  };
</script>

  <script src="/vendor/sha256.min.js"></script>
<script src="/js/auth.js"></script>
<script src="/js/index.js"></script>
<script src="/vendor/qrcode.min.js"></script>

  
    <link rel="icon" href="/favicon.ico">
    <link rel="apple-touch-icon" href="/images/favicon.ico">
  

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/index.css">
<link rel="stylesheet" href="/styles/components/highlight/highlight.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  
</head>
  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="site-header">
  <div class="site-header-brand">
    
      <span class="site-header-brand-title">
        <a href="/">踏路</a>
      </span>
    
    
      <span class="site-header-brand-motto"> | 静心思考认真生活</span>
    
  </div>
  <div class="site-header-right">
    <nav class="site-header-navigation">
      
        <a href="/" target="_self">首页</a>
      
        <a href="/archives/" target="_self">归档</a>
      
        <a href="/categories/Projects/" target="_self">项目</a>
      
        <a href="/tags/" target="_self">标签云</a>
      
        <a href="/categories/" target="_self">分类云</a>
      
        <a href="/friends/" target="_self">友链</a>
      
        <a href="/about/" target="_self">关于</a>
      
    </nav>
    <div class="site-header-btn">
      
        <a href="https://github.com/syw2014" target="_blank" id="site-github">
          <i class="fa fa-github-alt"></i>
        </a>
      
      <a href="javascript:void(0);" id="site-search">
        <i class="fa fa-search"></i>
      </a>
      <a href="javascript:void(0);" id="site-nav-btn">
        <i class="fa fa-ellipsis-v"></i>
      </a>
    </div>
  </div>
</header>
<nav class="table-content" id="site-nav">
  <div class="table-content-title">
    <span>导航</span>
  </div>
  <div class="table-content-main">
    <ol class="toc">
      
        <li class="toc-item">
          <a href="/" target="_self">
            首页
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/archives/" target="_self">
            归档
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/categories/Projects/" target="_self">
            项目
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/tags/" target="_self">
            标签云
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/categories/" target="_self">
            分类云
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/friends/" target="_self">
            友链
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/about/" target="_self">
            关于
          </a>
        </li>
      
    </ol>
  </div>
</nav>
<div id="site-process"></div>
    <main>
      
  <div class="passage">
  <div class="passage-meta">
    <span>
      <i class="fa fa-calendar"></i>2018-01-13
    </span>
    
      <span>
        | <a href="/categories/CS244n/"><i class="fa fa-bookmark"></i>CS244n</a>
      </span>
    
    
      <span>
        | <i class="fa fa-unlock-alt"></i>UNLOCK
      </span>
    
  </div>
  <h1 class="passage-title">
    CS244n lecture3 Notes:高级词向量
  </h1>
  
  <article class="passage-article">
    </p>
<h2 id="word2vec基本思想回顾"><a href="#word2vec基本思想回顾" class="headerlink" title="word2vec基本思想回顾"></a>word2vec基本思想回顾</h2><ul>
<li>遍历corpus中每个词</li>
<li>预测每个窗口中心词周围的词</li>
<li>计算该窗口内梯度，利用SGD对参数（这里参数即是vector）优化</li>
</ul>
<h2 id="word2vec可能存在的问题"><a href="#word2vec可能存在的问题" class="headerlink" title="word2vec可能存在的问题"></a>word2vec可能存在的问题</h2><ul>
<li>梯度稀疏<br>假设词窗口大小为m的话，仅能够得到2m+1个词，因此梯度会非常稀疏。<br>对于这种情况，有时只对词窗口中出现过的词对应的词向量进行更新。这样一来对于权重矩阵W或者（词向量矩阵）我们只需要更新特定行或列，或者为每个词语到词向量建立hash映射。但是如果有上百万个词时，向量的更新量会非常大。</li>
</ul>
<h2 id="用Negative-Sampling-加速计算"><a href="#用Negative-Sampling-加速计算" class="headerlink" title="用Negative Sampling 加速计算"></a>用Negative Sampling 加速计算</h2><p>在skip-gram模型中，如图所示<br><img src="https://i.imgur.com/BKzW0hg.png" alt="skip-gram"></p>
<p>在上式中，softmax分母归一化操作需要很大的计算量，因为需要遍历整个词典计算点积总和，所以在作业1中采用negative sampling 来实现skip gram model。负采样的主要思想是，训练一个LR二分类器，正例是中心词和它周围词构成的词对，负样本是中心词和在词典中随机选取的词构成的词对。</p>
<p>在这篇文献“Distributed RepresentaRons of Words and Phrases<br>and their Compositionality”中，采用negative sampling来实现SG模型，总体的目标函数为，<br><img src="http://upload-images.jianshu.io/upload_images/2423131-d669b2eacab30255.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>其中，T代表总词窗口的个数也即是迭代次数，k是负采样个数.在目标函数中采用Sigmod函数，函数形式和曲线如图所示。p(w)是某个unigram分布。负采样具体介绍略。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-6ed6eeaf3cc6d660.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>目标函数简化后为<br><img src="http://upload-images.jianshu.io/upload_images/2423131-74ecb225abfd01fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>函数有两部分构成，加号左侧第一部分代表中心词和周围词真正共现的概率，后一部分是中心词和随机采样词共现的概率，因此优化的目标是使真正共现词概率最大化(前一部分)，非共现词概率最小化(后者)。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/2423131-d212f74c1ed57311.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>在负采样unigram 分布p(w)的0.75次幂进行采样，一个目的是用来平滑，同时也保证了频率低的词也可以经常被采样到。</p>
<h2 id="word2vec-总结。"><a href="#word2vec-总结。" class="headerlink" title="word2vec 总结。"></a>word2vec 总结。</h2><ul>
<li>遍历语料库中每一个词，</li>
<li>预测每个词周围词</li>
<li>每次预测出一个共现词<br>这样就引出了一个问题，为什么我们不能直接找共现词而不经过这种遍历？因word2vec对于参数的更新是在一个窗口或者某几个窗口之后。答案是肯定，早之前就有对词共现的研究—词共现矩阵，主要有两种方式，一种是基于整个文档形成，另一种是基于窗口构建矩阵，这种思想就是Latent Senmentic Analysis，和word2vec一样，利用窗口在每个词周围获取syntatic句法（POS）和语义信息。</li>
</ul>
<h2 id="直接构建词共现矩阵"><a href="#直接构建词共现矩阵" class="headerlink" title="直接构建词共现矩阵"></a>直接构建词共现矩阵</h2><p>我们通过找共现词然后预测出最终合适的词，那这就出来个问题，为什么我们不能基于语料库直接找共现词？之所以word2vec采用这种方式是因为参数的更新是在一个窗口或者某几个窗口之后，也就意味着需要很多次迭代才能找到共现词。<br>直接寻找共现词是完全可以的，早期的学者就有对词共现的研究—构建词共现矩阵，它主要有两种方式，一种是基于整篇文档构成词-文档矩阵，另一种是基于窗口构建矩阵，这种思想就是常说的Latent Senmentic Analysis(LSA)，和word2vec一样，它利用窗口在每个词周围获取syntatic句法（POS）和语义信息。</p>
<h2 id="基于窗口构建共现矩阵示例"><a href="#基于窗口构建共现矩阵示例" class="headerlink" title="基于窗口构建共现矩阵示例"></a>基于窗口构建共现矩阵示例</h2><p>假设有以个语料库（这里指句子集合）</p>
<p><img src="http://upload-images.jianshu.io/upload_images/2423131-99a7f274592ff7d3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="j"></p>
<p>分词，根据词窗口距离统计词共现次数，词窗口一般选择1-10，这里选择1，即前后一个位置，可得到词共现矩阵为，<br><img src="http://upload-images.jianshu.io/upload_images/2423131-b1a3dad4efdbadfa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>矩阵中每一行或列都可以看做是词的一个向量，可以直接用这个向量参与一些NLP任务。但这种采用简单方式得到的词向量会有如下限制，</p>
<ul>
<li>向量维度和词典大小保持一致，当词典增大，维度就发生改变</li>
<li>词典通常很大，所以向量维度很大，需要更多的存储空间</li>
<li>可以发现矩阵存在稀疏性问题，对不同模型鲁棒性差</li>
</ul>
<p>通过采用SVD将向量转换为25-1000的低纬度向量。这其中也会牵涉到一些优化方法如对高频词停用词进行过滤，采用皮尔逊系数代替词频值。SVD进行计算词向量存在如下问题，比如，计算复杂度大，对于一个nxm的矩阵复杂度为O（mn^2），不易处理新词或文档；由于采用慈功贤矩阵获得词向量有诸多限制，是否可以基于此获得更高效的词向量？</p>
<h2 id="用SVD对词共现矩阵降维"><a href="#用SVD对词共现矩阵降维" class="headerlink" title="用SVD对词共现矩阵降维"></a>用SVD对词共现矩阵降维</h2><p>通过采用SVD将词共现矩阵转换为25-1000的低纬度向量可以得到更好的词向量，如图。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-eb2118d10a38a2a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>这其中可以采用如下tricks，</p>
<ul>
<li>对高频词停用词进行过滤</li>
<li>采用皮尔逊系数代替词频值</li>
<li>对于频率相同的词窗口进行重采样</li>
</ul>
<h2 id="SVD降维存在的问题"><a href="#SVD降维存在的问题" class="headerlink" title="SVD降维存在的问题"></a>SVD降维存在的问题</h2><p>SVD计算复杂度大，对于一个N x M的矩阵复杂度为O（mn^2），不易合并新词或新文档；</p>
<h2 id="基于频率和直接预测共现词方法对比"><a href="#基于频率和直接预测共现词方法对比" class="headerlink" title="基于频率和直接预测共现词方法对比"></a>基于频率和直接预测共现词方法对比</h2><p><img src="http://upload-images.jianshu.io/upload_images/2423131-b3cc422d77b6090c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>对比如上图。<br>基于频率统计的方法有LSA, HAL, COALS, Hellinger-PCA,具有如下特点，</p>
<ul>
<li>训练速度快</li>
<li>充分利用统计性</li>
<li>主要用来获取词间的相似性</li>
<li>无法扩展到大规模语料</li>
</ul>
<p>直接预测共现词获得词向量的方法有NNLM,HLBL,RNN,Skip-gram/CBOW,有如下特点</p>
<ul>
<li>性能随语料库大小而变</li>
<li>不能充分利用统计规律</li>
<li>可以提升其他NLP任务效果</li>
<li>能够后的词相似度以外的pattern</li>
</ul>
<p>既然基于计数和直接预测都有优缺点，可否直接将二者进行结合成新的模型？</p>
<h2 id="最好的词向量模型Glove"><a href="#最好的词向量模型Glove" class="headerlink" title="最好的词向量模型Glove"></a>最好的词向量模型Glove</h2><p>模型目标函数为：<br><img src="http://upload-images.jianshu.io/upload_images/2423131-9e19f0afb651831f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>这里P(ij)是两个词共现次数，f为max函数，函数曲线如下图<br><img src="http://upload-images.jianshu.io/upload_images/2423131-81702a161dd69ccb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>该模型所具有一下好处，</p>
<ul>
<li>训练速度快</li>
<li>对大规模语料也适用</li>
<li>对于小语料库、小向量也有较好额效果</li>
</ul>
<p>我们知道在模型总我们对于每个词我们都有两词向量u和v，他们中都含有共现信息，实践证明，将二者合并时最佳的选择。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/2423131-2190813b1f53a0ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>这节课中有一部分hightlight talk，会单独拿出来进行记录。</p>
<h2 id="词向量评价"><a href="#词向量评价" class="headerlink" title="词向量评价"></a>词向量评价</h2><p>对词向量的评价和NLP传统评测方法一样，有两种内部(Intrinsic)和外部(extrinsic).</p>
<ul>
<li>内部评价指标或方式<br>专门设计单独的试验，由人工标注词语或句子相似度，与模型结果对比。好处是计算速度快，但不知道对实际应用有无帮助。</li>
<li>外部评价<br>通过对外部实际应用的效果提升来体现。耗时较长，不能排除是否是新的词向量与旧系统的某种契合度产生。需要至少两个subsystems同时证明。这类评测中，往往会用pre-train的向量在外部任务的语料上retrain。</li>
</ul>
<h3 id="词向量内部评价示例"><a href="#词向量内部评价示例" class="headerlink" title="词向量内部评价示例"></a>词向量内部评价示例</h3><p>词向量类推，这一是word2vec出来之后经常会拿来举例的。“A对于B，就像C对于D”，这可以通过余弦相似度夹角得到。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-7db7799942b3cab5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>最终结果发现，将他们进行可视化之后，可以看出每个组之间的形式还是很类似的。<br><img src="http://upload-images.jianshu.io/upload_images/2423131-83ae625858065059.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>对于词向量外部评价，就是通过词向量可以直接提升任务效果，如NER，分类等。</p>
  </article>
  <aside class="table-content" id="site-toc">
  <div class="table-content-title">
    <i class="fa fa-arrow-right fa-lg" id="site-toc-hide-btn"></i>
    <span>目录</span>
  </div>
  <div class="table-content-main">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#word2vec基本思想回顾"><span class="toc-text">word2vec基本思想回顾</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#word2vec可能存在的问题"><span class="toc-text">word2vec可能存在的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用Negative-Sampling-加速计算"><span class="toc-text">用Negative Sampling 加速计算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#word2vec-总结。"><span class="toc-text">word2vec 总结。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#直接构建词共现矩阵"><span class="toc-text">直接构建词共现矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基于窗口构建共现矩阵示例"><span class="toc-text">基于窗口构建共现矩阵示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用SVD对词共现矩阵降维"><span class="toc-text">用SVD对词共现矩阵降维</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVD降维存在的问题"><span class="toc-text">SVD降维存在的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#基于频率和直接预测共现词方法对比"><span class="toc-text">基于频率和直接预测共现词方法对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#最好的词向量模型Glove"><span class="toc-text">最好的词向量模型Glove</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#词向量评价"><span class="toc-text">词向量评价</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#词向量内部评价示例"><span class="toc-text">词向量内部评价示例</span></a></li></ol></li></ol>
  </div>
</aside>
  
    <aside class="passage-copyright">
      <div>本文作者: 悯生</div>
      
        <div>
          原文链接: 
          <a href="" target="_blank">https://helixn.com/passages/2018-01-13-cs244n-notes3/</a>
        </div>
      
      <div>
        版权声明: 本博客所有文章除特别声明外, 均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议. 转载请注明出处!
      </div>
    </aside>
  
  
    <div class="passage-tags">
     
      <a href="/tags/cs244n/"><i class="fa fa-tags"></i>cs244n</a>
     
      <a href="/tags/NLP/"><i class="fa fa-tags"></i>NLP</a>
     
      <a href="/tags/DL/"><i class="fa fa-tags"></i>DL</a>
     
      <a href="/tags/word2vec/"><i class="fa fa-tags"></i>word2vec</a>
    
    </div>
  
</div>

    </main>
    
      
<div class="site-comment-contanier" data-plateform="leancloud">
  
    <p id="site-comment-info">
      <i class="fa fa-spinner fa-spin"></i> 评论加载中
    </p>
    <div id="site-comment"></div>
  
</div>
    
    <div class="site-footer-wrapper">
  <footer class="site-footer">
    
      
        <div class="site-footer-col">
          <h5 class="site-footer-title">博客推荐</h5>
          
            <span class="site-footer-item">
              <a href="https://helixn.com/" target="_blank">踏路</a>
            </span>
          
            <span class="site-footer-item">
              <a href="https://www.jianshu.com/u/c44c1c14b248" target="_blank">简书</a>
            </span>
          
        </div>
      
    
    <div class="site-footer-info">
      <i class="fa fa-clock-o"></i> 本站已稳定运行<span id="site-time"></span>
    </div>
    
      <div class="site-footer-info">
        <i class="fa fa-paw"></i> 您是本站第30<span id="site-count"></span>位访客
      </div>
    
    
      <div class="site-footer-info">
        <i class="fa fa-at"></i> Email: jerryshi0110@gmail.com
      </div>
    
    <div class="site-footer-info">
      <i class="fa fa-copyright"></i> 
      2016-2019
      Created by <a href="https://www.helixn.com/" target="_blank">JerryShi</a>.
      All rights reserved.
    </div>
  </footer>
</div>
    <div id="site-layer" style="display:none;">
  <div class="site-layer-content">
    <div class="site-layer-header">
      <span class="site-layer-header-title" id="site-layer-title"></span>
      <i class="fa fa-close" id="site-layer-close"></i>
    </div>
    <div class="site-layer-body" id="site-layer-container">
      <div class="site-layer-input" id="site-layer-search" style="display: none;">
        <input type="text">
        <i class="fa fa-search"></i>
      </div>
      
        <div class="site-layer-reward" id="site-layer-reward" style="display: none;">
          
            <div>
              <img src="/images/wechat.png" alt="WeChat">
              
                <p>WeChat</p>
              
            </div>
          
            <div>
              <img src="/images/alipay.png" alt="AliPay">
              
                <p>AliPay</p>
              
            </div>
          
        </div>
      
      <div id="site-layer-welcome" style="display:none;"></div>
    </div>
  </div>
</div>
    

<div class="bottom-bar">
  <div class="bottom-bar-left">
    <a href="/passages/2018-01-20-cs244n-notes2/" data-enable="true">
      <i class="fa fa-arrow-left"></i>
    </a>
    <a href="/passages/2018-01-08-cs244n-notes1/" data-enable="true">
      <i class="fa fa-arrow-right"></i>
    </a>
  </div>
  <div class="bottom-bar-right">
    <a href="javascript:void(0);" data-enable="true" id="site-toc-show-btn">
      <i class="fa fa-bars"></i>
    </a>
    
      <a href="#site-comment" data-enable="true">
        <i class="fa fa-commenting"></i>
      </a>
    
    <a href="javascript:void(0);" id="site-toggle-share-btn">
      <i class="fa fa-share-alt"></i>
    </a>
    
      <a href="javascript:void(0);" id="site-reward">
        <i class="fa fa-thumbs-up"></i>
      </a>
    
    <a href="javascript:void(0);" id="back-top-btn">
      <i class="fa fa-chevron-up"></i>
    </a>
  </div>
</div>
    <div id="share-btn">
  
    <a id="share-btn-twitter" href="javascript:void(0);" target="_blank">
      <i class="fa fa-twitter"></i>
    </a>
  
  
    <a id="share-btn-facebook" href="javascript:void(0);" target="_blank">
      <i class="fa fa-facebook"></i>
    </a>
  
  
    <a id="share-btn-weibo" href="javascript:void(0);" target="_blank">
      <i class="fa fa-weibo"></i>
    </a>
  
  
    <a id="share-btn-qq" href="javascript:void(0);" target="_blank">
      <i class="fa fa-qq"></i>
    </a>
  
  
    <a id="share-btn-wechat" href="javascript:void(0);" target="_blank">
      <i class="fa fa-wechat"></i>
    </a>
  
</div>
    


  <script async>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




    
  </body>
</html>