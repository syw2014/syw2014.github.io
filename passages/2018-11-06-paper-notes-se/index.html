<!DOCTYPE html>
<html>
  
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta name="author" content="悯生" />
  
  
  <title>论文笔记 - A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING | 踏路</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Paper Notes,Attention,Sentence Embeding,Sentiment Analysis," />
  

  
  <meta name="description" content="论文特点和传统句子编码不同，传统方法对句子编码后是一个d 的Vector，而该论文方法是将句子编码为一个 r x d 的Matrix，原因是作者认为一个vector的表示只能突出句子中相关words 和phrase的表示，而实际情况一个句子的语义含义会r 部分构成，因此作者将一个句子的编码表示成一个matrixAttenion， 句子被表示成矩阵，那么此时的attention 权重A也是一个r x n，penalization term， 表示的惩罚机制.作者认为经过attention机制之后的表示会存在冗余表示的情况，因此需要一个惩罚机制对attention 权重处理来保证最终表示的多样性。">

  

  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.1/dist/av-min.js" async></script>
  

  
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
  

  
    <script src="//unpkg.com/valine/dist/Valine.min.js" async></script>
  

  

  <script>
  // theme-ad's config script
  // it can be used in every script
  
  window.AD_CONFIG = {
    leancloud: {"appid":"6sEpjxpdQ0zFbHII2mSfaKib-gzGzoHsz","appkey":"qdahfkeMY3jcS1ebdMnOQr7I","comment":true,"count":true},
    welcome: {"enable":true,"interval":10},
    start_time: "2016-02-10",
    passwords: ["efe07af7441da2b69c4a41e42e73be4db47f66010a56900788a458354a7373ec", ],
    is_post: true,
    lock: false,
    author: "悯生",
    share: {"twitter":true,"facebook":true,"weibo":true,"qq":true,"wechat":true},
    mathjax: true,
    page_type: "",
    root: "/"
  };
</script>

  <script src="/vendor/sha256.min.js"></script>
<script src="/js/auth.js"></script>
<script src="/js/index.js"></script>
<script src="/vendor/qrcode.min.js"></script>

  
    <link rel="icon" href="/favicon.ico">
    <link rel="apple-touch-icon" href="/images/favicon.ico">
  

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/index.css">
<link rel="stylesheet" href="/styles/components/highlight/highlight.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  
</head>
  <body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="site-header">
  <div class="site-header-brand">
    
      <span class="site-header-brand-title">
        <a href="/">踏路</a>
      </span>
    
    
      <span class="site-header-brand-motto"> | 静心思考认真生活</span>
    
  </div>
  <div class="site-header-right">
    <nav class="site-header-navigation">
      
        <a href="/" target="_self">首页</a>
      
        <a href="/archives/" target="_self">归档</a>
      
        <a href="/categories/Projects/" target="_self">项目</a>
      
        <a href="/tags/" target="_self">标签云</a>
      
        <a href="/categories/" target="_self">分类云</a>
      
        <a href="/friends/" target="_self">友链</a>
      
        <a href="/about/" target="_self">关于</a>
      
    </nav>
    <div class="site-header-btn">
      
        <a href="https://github.com/syw2014" target="_blank" id="site-github">
          <i class="fa fa-github-alt"></i>
        </a>
      
      <a href="javascript:void(0);" id="site-search">
        <i class="fa fa-search"></i>
      </a>
      <a href="javascript:void(0);" id="site-nav-btn">
        <i class="fa fa-ellipsis-v"></i>
      </a>
    </div>
  </div>
</header>
<nav class="table-content" id="site-nav">
  <div class="table-content-title">
    <span>导航</span>
  </div>
  <div class="table-content-main">
    <ol class="toc">
      
        <li class="toc-item">
          <a href="/" target="_self">
            首页
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/archives/" target="_self">
            归档
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/categories/Projects/" target="_self">
            项目
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/tags/" target="_self">
            标签云
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/categories/" target="_self">
            分类云
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/friends/" target="_self">
            友链
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/about/" target="_self">
            关于
          </a>
        </li>
      
    </ol>
  </div>
</nav>
<div id="site-process"></div>
    <main>
      
  <div class="passage">
  <div class="passage-meta">
    <span>
      <i class="fa fa-calendar"></i>2018-11-06
    </span>
    
      <span>
        | <a href="/categories/Paper-Notes/"><i class="fa fa-bookmark"></i>Paper Notes</a>
      </span>
    
    
      <span>
        | <i class="fa fa-unlock-alt"></i>UNLOCK
      </span>
    
  </div>
  <h1 class="passage-title">
    论文笔记 - A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING
  </h1>
  
  <article class="passage-article">
    <h2 id="论文中模型框图"><a href="#论文中模型框图" class="headerlink" title="论文中模型框图"></a>论文中模型框图</h2><p>系统架构图如下所示：<br><img src="https://upload-images.jianshu.io/upload_images/2423131-f67889761d5f918a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="论文模型过程介绍"><a href="#论文模型过程介绍" class="headerlink" title="论文模型过程介绍"></a>论文模型过程介绍</h2><p>该部分详细介绍论文中模型具体过程。（<em>先说明一下输入数据，每个sample，是有个sentence， token id 序列，是经过padding后到一个固定的sequence length</em>）<br>Bidirectional LSTM encoding —&gt; Attention Mechanism —&gt; Sentence Embedding —&gt; Add Penalization Term to Loss<br>1 . LSTM Encoding<br>设输入序列如下：</p>
<script type="math/tex; mode=display">S = (w_1, w_2,...,w_n)</script><p>其中，$n$表示句子长度，$w<em>i$表示句子中第$i$个词的embedding vector， 维度为$d$，那么$S=[W]</em>{n\times d}$,将sentence输入到双向LSTM中得到隐藏层输出,</p>
<script type="math/tex; mode=display">\vec{h_t}=\vec{LSTM}(w_t, \vec{h_{t-1}})</script><script type="math/tex; mode=display">\overleftarrow{h_t}=\overleftarrow{LSTM}(w_t, \overleftarrow{h_{t+1}})</script><p>其中，$\vec{h<em>t}$ 和$\overleftarrow{h_t}$表示双向LSTM的隐藏层输出，设单向隐藏层单元数为$u$即每个LSTM隐藏层输出维度为$u$，把双向LSTM的输出进行拼接，得到sentence的隐藏层输出$$H=[]</em>{n \times 2u}$$，</p>
<script type="math/tex; mode=display">H=（h_1, h_2,...,h_n）</script><p>2 . Attention<br>为了将变长的sentence编码为一个固定长度的编码，因此加入$attention$机制。</p>
<script type="math/tex; mode=display">\text{a}=softmax(w_{s2}tanh(W_{s1}H^T))</script><p>其中，$w<em>{s2}$是一个维度为$d_a$的向量，$d_a$为超参数，$$W</em>{s2}=[]<em>{d_a \times 2u}<script type="math/tex">为参数矩阵,那么权重向量维度,</script>\text{a}=[]</em>{1 \times d<em>a} \cdot []</em>{d<em>a \times 2u} \cdot []</em>{2u \times n}=[]_{1\times n}<script type="math/tex">，其中</script>\text{a}$$中的每个元素$a_i$表示sentence中每个词$w_i$的权重。经过注意力之后新的表示计算公式为</p>
<script type="math/tex; mode=display">m=\text{a}H</script><p>维度为，<script type="math/tex">m=[]_{1 \times n} \cdot []_{n \times 2u}=[]_{1 \times 2u}</script><br>m是经过注意力机制之后新的sentence embedding，这是通常的做法，但是作者认为，这种注意力向量生成的表示向量，往往只关注句子中某个特定语义的短语或词，作者认为表示向量中应该包含多个层面语义，尤其是对于一个长句子更应该会有多个语义部分构成，因此作者对上述注意力机制进行改进，使得注意力权重有$r$部分构成，则新的注意力权重公式如下，</p>
<script type="math/tex; mode=display">A=softmax(W_{s2}tanh(W_{s1}H^T))</script><p>其中，<script type="math/tex">W_{s1}=[]_{r \times d_a}</script>和<script type="math/tex">W_{s2}=[]_{d_a \times 2u}</script>都是参数矩阵，$d<em>a$依然是超参数，则计算出的注意力矩阵维度为$$A=[]</em>{r \times d<em>a} \cdot []</em>{d<em>a \times 2u} \cdot []</em>{2u \times n}= []_{r \times n}$$<br>从计算结果可以看到，注意力权重矩阵有$r$部分构成，则经过注意力计算后，新的sentence embedding为：</p>
<script type="math/tex; mode=display">M=AH</script><p>维度为，<script type="math/tex">M=[]_{r \times n} \cdot []_{n \times 2u}=[]_{r \times 2u}</script><br>3 . Penalization Term<br>对sentence embedding <script type="math/tex">M</script>分析，作者认为如果注意力权重总是提供相似的<script type="math/tex">r</script>个权重的话，编码表示会存在冗余的情况，因此作者设计了一种惩罚机制，以使的句子表示具有多样性。<br>对于任意两个权重向量，计算他们间的多样性的最好方式是采用<strong>Kullback Leibler divergence</strong>,但作者发现LK散度在他们的情况下并不稳定，猜测原因是他们采用的是最大化一组KL divergence，而通常做法是最小化一个KL 散度；同时他们也发现，权重矩阵$A$在不同的softmax 输出单元上很小有的甚至为0，这么多的0也导致了训练不稳定。<br>由于KL存在这些不足，作者又采用了另外一种方式, <strong>Frobenius norm of a matrix</strong>,计算公式如下，</p>
<script type="math/tex; mode=display">P = \parallel (AA^T - I) \parallel _{F}^{2}</script><p>其中$\parallel \bullet \parallel_F$ 表示的是矩阵的<strong>Frobenius norm</strong>，它在加入到模型loss时会有个权重系数。<br>因为注意力权重向量是经过softmax运算得到，所以矩阵$A$中两个向量元素$a_i$和$a_j$可以看做是两个概率分布，则对于<script type="math/tex">i\neq j</script>时，如下，</p>
<script type="math/tex; mode=display">0 < a_{ij} = \Sigma_{k=1}^{n}a_k^ia_k^j < 1</script><p>其中，$a<em>i$和$a_j$ 是向量$\text{a_i}$和$\text{a_j}$中的元素，如果两个分布间没有重叠部分，则$$a</em>{ij}=0<script type="math/tex">，反之，该值为一个大于0的值，极端情况下，如果两个分布是相同的，都集中在一个词上，则该值为1,从而使得向量</script>\text{a^i}$$尽量只关注与一小部分词，以减少表示的冗余性。</p>
<h2 id="个人点评"><a href="#个人点评" class="headerlink" title="个人点评"></a>个人点评</h2><p>对于NLP中的任务来说，目前主要还是集中在寻找一个更加贴切、能够包含丰富语义的表示方法，该论文认为每个句子的文本表示不能仅仅用一个向量表示，向量表示只关注了句子中部分词或短语，句子的语义表示更应该是多个层面、多个部分的，从实际的角度来看此方法存在一定合理性，能够对于NLP任务如情感分类、文本分类带来一定提升。</p>
  </article>
  <aside class="table-content" id="site-toc">
  <div class="table-content-title">
    <i class="fa fa-arrow-right fa-lg" id="site-toc-hide-btn"></i>
    <span>目录</span>
  </div>
  <div class="table-content-main">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#论文中模型框图"><span class="toc-text">论文中模型框图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#论文模型过程介绍"><span class="toc-text">论文模型过程介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#个人点评"><span class="toc-text">个人点评</span></a></li></ol>
  </div>
</aside>
  
    <aside class="passage-copyright">
      <div>本文作者: 悯生</div>
      
        <div>
          原文链接: 
          <a href="" target="_blank">http://syw2014.github.io/passages/2018-11-06-paper-notes-se/</a>
        </div>
      
      <div>
        版权声明: 本博客所有文章除特别声明外, 均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议. 转载请注明出处!
      </div>
    </aside>
  
  
    <div class="passage-tags">
     
      <a href="/tags/Attention/"><i class="fa fa-tags"></i>Attention</a>
     
      <a href="/tags/Sentence-Embeding/"><i class="fa fa-tags"></i>Sentence Embeding</a>
     
      <a href="/tags/Sentiment-Analysis/"><i class="fa fa-tags"></i>Sentiment Analysis</a>
    
    </div>
  
</div>

    </main>
    
      
<div class="site-comment-contanier" data-plateform="leancloud">
  
    <p id="site-comment-info">
      <i class="fa fa-spinner fa-spin"></i> 评论加载中
    </p>
    <div id="site-comment"></div>
  
</div>
    
    <div class="site-footer-wrapper">
  <footer class="site-footer">
    
      
        <div class="site-footer-col">
          <h5 class="site-footer-title">博客推荐</h5>
          
            <span class="site-footer-item">
              <a href="https://www.mskitech.com/" target="_blank">踏路</a>
            </span>
          
            <span class="site-footer-item">
              <a href="https://www.jianshu.com/u/c44c1c14b248" target="_blank">简书</a>
            </span>
          
        </div>
      
    
    <div class="site-footer-info">
      <i class="fa fa-clock-o"></i> 本站已稳定运行<span id="site-time"></span>
    </div>
    
      <div class="site-footer-info">
        <i class="fa fa-paw"></i> 您是本站第30<span id="site-count"></span>位访客
      </div>
    
    
      <div class="site-footer-info">
        <i class="fa fa-at"></i> Email: jerryshi0110@gmail.com
      </div>
    
    <div class="site-footer-info">
      <i class="fa fa-copyright"></i> 
      2019 <a href="https://github.com/dongyuanxin/theme-ad/" target="_blank">Theme-AD</a>.
      Created by <a href="https://www.mskitech.com/" target="_blank">GodBMW</a>.
      All rights reserved.
    </div>
  </footer>
</div>
    <div id="site-layer" style="display:none;">
  <div class="site-layer-content">
    <div class="site-layer-header">
      <span class="site-layer-header-title" id="site-layer-title"></span>
      <i class="fa fa-close" id="site-layer-close"></i>
    </div>
    <div class="site-layer-body" id="site-layer-container">
      <div class="site-layer-input" id="site-layer-search" style="display: none;">
        <input type="text">
        <i class="fa fa-search"></i>
      </div>
      
        <div class="site-layer-reward" id="site-layer-reward" style="display: none;">
          
            <div>
              <img src="/images/wechat.png" alt="WeChat">
              
                <p>WeChat</p>
              
            </div>
          
            <div>
              <img src="/images/alipay.png" alt="AliPay">
              
                <p>AliPay</p>
              
            </div>
          
        </div>
      
      <div id="site-layer-welcome" style="display:none;"></div>
    </div>
  </div>
</div>
    

<div class="bottom-bar">
  <div class="bottom-bar-left">
    <a href="/passages/2019-05-08-deepfm-implementation/" data-enable="true">
      <i class="fa fa-arrow-left"></i>
    </a>
    <a href="/passages/2018-05-30-paper-notes-dssm/" data-enable="true">
      <i class="fa fa-arrow-right"></i>
    </a>
  </div>
  <div class="bottom-bar-right">
    <a href="javascript:void(0);" data-enable="true" id="site-toc-show-btn">
      <i class="fa fa-bars"></i>
    </a>
    
      <a href="#site-comment" data-enable="true">
        <i class="fa fa-commenting"></i>
      </a>
    
    <a href="javascript:void(0);" id="site-toggle-share-btn">
      <i class="fa fa-share-alt"></i>
    </a>
    
      <a href="javascript:void(0);" id="site-reward">
        <i class="fa fa-thumbs-up"></i>
      </a>
    
    <a href="javascript:void(0);" id="back-top-btn">
      <i class="fa fa-chevron-up"></i>
    </a>
  </div>
</div>
    <div id="share-btn">
  
    <a id="share-btn-twitter" href="javascript:void(0);" target="_blank">
      <i class="fa fa-twitter"></i>
    </a>
  
  
    <a id="share-btn-facebook" href="javascript:void(0);" target="_blank">
      <i class="fa fa-facebook"></i>
    </a>
  
  
    <a id="share-btn-weibo" href="javascript:void(0);" target="_blank">
      <i class="fa fa-weibo"></i>
    </a>
  
  
    <a id="share-btn-qq" href="javascript:void(0);" target="_blank">
      <i class="fa fa-qq"></i>
    </a>
  
  
    <a id="share-btn-wechat" href="javascript:void(0);" target="_blank">
      <i class="fa fa-wechat"></i>
    </a>
  
</div>
    


  <script async>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




    
  </body>
</html>